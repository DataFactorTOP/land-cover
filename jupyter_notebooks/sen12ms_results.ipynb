{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze SEN12MS Segmentation + Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import land_cover_utils\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# import config\n",
    "config_dir = '/home/lucas/land-cover/config.json'\n",
    "with open(config_dir, 'r') as f:\n",
    "    config = json.load(f, object_hook=land_cover_utils.json_keys_to_int)\n",
    "    \n",
    "label_encoder = land_cover_utils.get_label_encoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions + labels directories\n",
    "segmentation_results_dir = '/data/lucas/sen12ms_segmentation_predictions'\n",
    "segmentation_labels_dir = '/data/datasets/sen12ms_segmentation'\n",
    "\n",
    "continent_seasons = os.listdir(segmentation_labels_dir)\n",
    "\n",
    "def get_segmentation_model_prediction_dirs(mode):\n",
    "    '''\n",
    "    Get segmentation model directories\n",
    "    mode = \"by_season\" or \"by_continent\"\n",
    "    '''\n",
    "    model_names = os.listdir(os.path.join(segmentation_results_dir, mode))\n",
    "    return [os.path.join(segmentation_results_dir, mode, model_name) for model_name in model_names]\n",
    "\n",
    "def scene_dir_to_season_scene(scene_dir):\n",
    "    '''\n",
    "    E.g. '/data/datasets/sen12ms_subpatches/Africa-fall/scene_79' --> \"fall_79\"\n",
    "    '''\n",
    "    continent_season = scene_dir.split('/')[-2]\n",
    "    season = continent_season.split('-')[-1]\n",
    "    scene = int(scene_dir.split('_')[-1])\n",
    "    return \"{}_{}\".format(season, scene)\n",
    "\n",
    "def get_train_val_season_scenes(predictions_dir):\n",
    "    '''\n",
    "    Given a predictions filepath, get the corresponding train-val season_scenes\n",
    "    '''\n",
    "    if 'by_season' in predictions_dir:\n",
    "        train_val_splits_dir = '/home/lucas/land-cover/saved_models/by_season'\n",
    "    elif 'by_continent' in predictions_dir:\n",
    "        train_val_splits_dir = '/home/lucas/land-cover/saved_models/by_continent'\n",
    "    else:\n",
    "        return None\n",
    "    model_name = os.path.basename(predictions_dir)\n",
    "    train_val_split_file = os.path.join(train_val_splits_dir, \\\n",
    "                                        model_name + '_train-val-split.json')\n",
    "    train_val_split = json.load(open(train_val_split_file))\n",
    "    train_scene_dirs = train_val_split['train_scene_dirs']\n",
    "    val_scene_dirs = train_val_split['val_scene_dirs']\n",
    "    train_season_scenes = [scene_dir_to_season_scene(scene_dir) for scene_dir in train_scene_dirs]\n",
    "    val_season_scenes = [scene_dir_to_season_scene(scene_dir) for scene_dir in val_scene_dirs]\n",
    "    return train_season_scenes, val_season_scenes\n",
    "\n",
    "def get_scene_prediction_dirs_for_season(model_predictions_dir, season):\n",
    "    '''\n",
    "    Get full prediction scene_dirs for given model and season\n",
    "    '''\n",
    "    scene_dirs = []\n",
    "    continent_season_dirs = [continent_season for continent_season in os.listdir(model_predictions_dir) if season in continent_season]\n",
    "    continent_season_dirs = [os.path.join(model_predictions_dir, c_s) for c_s in continent_season_dirs]\n",
    "    for c_s_dir in continent_season_dirs:\n",
    "        scenes = os.listdir(c_s_dir)\n",
    "        scene_dirs.extend([os.path.join(c_s_dir, scene) for scene in scenes])\n",
    "    return scene_dirs\n",
    "\n",
    "def get_scene_prediction_dirs_for_continent(model_predictions_dir, continent):\n",
    "    '''\n",
    "    Get full prediction scene_dirs for given model and continent\n",
    "    '''\n",
    "    scene_dirs = []\n",
    "    continent_season_dirs = [continent_season for continent_season in os.listdir(model_predictions_dir) if continent in continent_season]\n",
    "    continent_season_dirs = [os.path.join(model_predictions_dir, c_s) for c_s in continent_season_dirs]\n",
    "    for c_s_dir in continent_season_dirs:\n",
    "        scenes = os.listdir(c_s_dir)\n",
    "        scene_dirs.extend([os.path.join(c_s_dir, scene) for scene in scenes])\n",
    "    return scene_dirs\n",
    "\n",
    "def get_sorted_patch_ids_from_scene_dir(scene_dir):\n",
    "    ''' get all patches from a given scene_dir '''\n",
    "    patches = os.listdir(scene_dir)\n",
    "    patches = [int(patch.split('_')[1].split('.')[0]) for patch in patches]\n",
    "    patches = sorted(patches)\n",
    "    return patches\n",
    "\n",
    "def get_segmentation_label_prediction_from_scene_patch(scene_dir, patch_id):\n",
    "    ''' get label array and prediction array from patch_id '''\n",
    "    # get label\n",
    "    continent_season_scene = '/'.join(scene_dir.split('/')[-2:])\n",
    "    landuse_path = os.path.join(segmentation_labels_dir, continent_season_scene, 'patch_{}'.format(patch_id), 'landuse.npy')\n",
    "    label = np.load(landuse_path)\n",
    "    # get prediction\n",
    "    patch_path = os.path.join(scene_dir, 'patch_{}.npz'.format(patch_id))\n",
    "    prediction = np.load(patch_path)['arr_0']\n",
    "    return label, prediction\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### By-Season Segmentation Results ###\n",
    "\n",
    "segmentation_season_model_results_dir = './results/segmentation_season_model_results.pkl'\n",
    "segmentation_season_model_results = {} # train_season -> test_season -> season_scene -> 'acc' or 'confusion'\n",
    "\n",
    "for model_predictions_dir in get_segmentation_model_prediction_dirs('by_season'):\n",
    "    train_season = model_predictions_dir.split('_season_')[-1].split('_')[0] # e.g. 'winter'\n",
    "    print('---------- Evaluating {} season segmentation model ----------\\n'.format(train_season))\n",
    "    segmentation_season_model_results[train_season] = {}\n",
    "    train_season_scenes, val_season_scenes = get_train_val_season_scenes(model_predictions_dir)\n",
    "    # iterate over all seasons\n",
    "    for season in config['all_seasons']:\n",
    "        print('--- Evaluating on season: {} ---\\n'.format(season))\n",
    "        segmentation_season_model_results[train_season][season] = {}\n",
    "        scene_dirs = get_scene_prediction_dirs_for_season(model_predictions_dir, season)\n",
    "        # iterate over all scenes\n",
    "        for scene_dir in scene_dirs:\n",
    "            # if model was trained on this scene, then skip\n",
    "            season_scene = scene_dir_to_season_scene(scene_dir)\n",
    "            print('evaluation season_scene: ', season_scene)\n",
    "            if season_scene in train_season_scenes:\n",
    "                print('scene was used for model training. skipping evaluation on this scene')\n",
    "                continue\n",
    "            labels, preds = [], []\n",
    "            # get labels, predictions from each patch in this scene\n",
    "            patch_ids = get_sorted_patch_ids_from_scene_dir(scene_dir)\n",
    "            # get label, predictions\n",
    "            for patch_id in patch_ids:\n",
    "                try:\n",
    "                    label, pred = get_segmentation_label_prediction_from_scene_patch(scene_dir, patch_id)\n",
    "                except:\n",
    "                    continue\n",
    "                assert pred.shape == (256,256) and label.shape == (256,256)\n",
    "                labels.append(label)\n",
    "                preds.append(pred)\n",
    "            # calculate results on this scene\n",
    "            labels, preds = np.array(labels).flatten(), np.array(preds).flatten()\n",
    "            confusion = np.array(confusion_matrix(labels, preds, labels=label_encoder.classes_)) # exclude unknown classes\n",
    "            acc = np.trace(confusion) / np.sum(confusion)\n",
    "            # store results in results dict\n",
    "            segmentation_season_model_results[train_season][season][season_scene] = {}\n",
    "            segmentation_season_model_results[train_season][season][season_scene]['acc'] = acc\n",
    "            segmentation_season_model_results[train_season][season][season_scene]['confusion'] = confusion\n",
    "            # pickle dump results dict\n",
    "            with open(segmentation_season_model_results_dir, 'wb') as f:\n",
    "                pickle.dump(segmentation_season_model_results, f)\n",
    "            # print status update\n",
    "            print('acc: ', acc)\n",
    "            print('confusion:\\n', confusion)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### By-Continent Segmentation Results ###\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "segmentation_continent_model_results_dir = './results/segmentation_continent_model_results.pkl'\n",
    "segmentation_continent_model_results = {} # train_season -> test_season -> season_scene -> 'acc' or 'confusion'\n",
    "\n",
    "for model_predictions_dir in get_segmentation_model_prediction_dirs('by_continent'):\n",
    "    train_continent = model_predictions_dir.split('_continent_')[-1].split('_FC-DenseNet')[0] # e.g. 'Africa'\n",
    "    print('---------- Evaluating {} continent segmentation model ----------\\n'.format(train_continent))\n",
    "    segmentation_continent_model_results[train_continent] = {}\n",
    "    train_season_scenes, val_season_scenes = get_train_val_season_scenes(model_predictions_dir)\n",
    "    # iterate over all seasons\n",
    "    for continent in config['all_continents']:\n",
    "        print('--- Evaluating on continent: {} ---\\n'.format(continent))\n",
    "        segmentation_continent_model_results[train_continent][continent] = {}\n",
    "        scene_dirs = get_scene_prediction_dirs_for_continent(model_predictions_dir, continent)\n",
    "        # iterate over all scenes\n",
    "        for scene_dir in scene_dirs:\n",
    "            # if model was trained on this scene, then skip\n",
    "            season_scene = scene_dir_to_season_scene(scene_dir)\n",
    "            print('evaluation season_scene: ', season_scene)\n",
    "            if season_scene in train_season_scenes:\n",
    "                print('scene was used for model training. skipping evaluation on this scene')\n",
    "                continue\n",
    "            labels, preds = [], []\n",
    "            # get labels, predictions from each patch in this scene\n",
    "            patch_ids = get_sorted_patch_ids_from_scene_dir(scene_dir)\n",
    "            # get label, predictions\n",
    "            for patch_id in patch_ids:\n",
    "                try:\n",
    "                    label, pred = get_segmentation_label_prediction_from_scene_patch(scene_dir, patch_id)\n",
    "                except:\n",
    "                    continue\n",
    "                assert pred.shape == (256,256) and label.shape == (256,256)\n",
    "                labels.append(label)\n",
    "                preds.append(pred)\n",
    "            # calculate results on this scene\n",
    "            labels, preds = np.array(labels).flatten(), np.array(preds).flatten()\n",
    "            confusion = np.array(confusion_matrix(labels, preds, labels=label_encoder.classes_)) # exclude unknown classes\n",
    "            acc = np.trace(confusion) / np.sum(confusion)\n",
    "            # store results in results dict\n",
    "            segmentation_continent_model_results[train_continent][continent][season_scene] = {}\n",
    "            segmentation_continent_model_results[train_continent][continent][season_scene]['acc'] = acc\n",
    "            segmentation_continent_model_results[train_continent][continent][season_scene]['confusion'] = confusion\n",
    "            # pickle dump results dict\n",
    "            with open(segmentation_continent_model_results_dir, 'wb') as f:\n",
    "                pickle.dump(segmentation_continent_model_results, f)\n",
    "            # print status update\n",
    "            print('acc: ', acc)\n",
    "            print('confusion:\\n', confusion)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
